% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/explain_model.R
\name{explain_model}
\alias{explain_model}
\title{Explain a Meta-Learner Model using DALEX}
\usage{
explain_model(
  meta_learner,
  plot,
  variable,
  n = 100,
  new_obs = NULL,
  group = NULL
)
}
\arguments{
\item{meta_learner}{An object of class \code{s_learner}, \code{t_learner}, or \code{x_learner} containing a fitted model, data, and treatment specification.}

\item{plot}{Type of plot to generate. Options include:
\itemize{
\item \code{"variable_importance"}: Importance of covariates on ITE
\item \code{"pdp"}: Partial Dependence Plot for a variable
\item \code{"ice"}: Individual Conditional Expectation plot for a variable
\item \code{"breakdown"}: Breakdown plot for a single observation
\item \code{"shap"}: SHAP plot for a single observation
}}

\item{variable}{The covariate for PDP/ICE plots (required if \code{plot} is \code{"pdp"} or \code{"ice"}).}

\item{n}{Number of observations or grid points to compute PDP/ICE profiles (default: 100).}

\item{new_obs}{A single observation for Breakdown or SHAP plots. If NULL, the first row of data is used.}

\item{group}{Optional grouping variable for clustered PDP/ICE plots. Should be a column in the original data.}
}
\value{
A \code{ggplot} object showing the selected interpretation plot.
}
\description{
Generates interpretable visualizations for causal meta-learners (S, T, X learners)
using the Individual Treatment Effect (ITE) as the target. Supports Variable Importance,
Partial Dependence (PDP), Individual Conditional Expectation (ICE), Breakdown, and SHAP plots.
}
\details{
This function creates a DALEX explainer for a fitted meta-learner and generates plots using
the \strong{Individual Treatment Effect (ITE)} as the target. The function automatically applies
any preprocessing recipe included in the meta-learner and extracts covariates for plotting.

\strong{Supported plots}:
\itemize{
\item Variable Importance (\code{model_parts})
\item PDP / ICE (\code{model_profile}) with optional grouping
\item Breakdown / SHAP (\code{predict_parts}) for individual observations
}

\strong{Notes for T/X Learners}:
\itemize{
\item The function works directly if the meta-learner stores \code{effect_measures$ITE}.
\item The \code{predict_ite} function automatically extracts ITE from the learner object.
\item Future extensions could include learner-specific diagnostics or aggregated ITE plots.
}
}
\examples{
\dontrun{
# S-learner PDP for variable "age"
explain_model(meta_learner = s_fit,
              plot = "pdp", variable = "age", n = 100)

# SHAP plot for the first observation
explain_model(meta_learner = s_fit,
              plot = "shap", n = 50)

# ICE plot grouped by "gender"
explain_model(meta_learner = s_fit,
              plot = "ice", variable = "income", n = 50, group = "gender")
}
}
